{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d18238b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>AboveMedianPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>856</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>548</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1262</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>920</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>608</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>756</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>642</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1145</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>836</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>7917</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>953</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>13175</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1542</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>9042</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1152</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>252</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>9717</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1078</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>9937</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1256</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>276</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LotArea  OverallQual  OverallCond  TotalBsmtSF  FullBath  HalfBath  \\\n",
       "0        8450            7            5          856         2         1   \n",
       "1        9600            6            8         1262         2         0   \n",
       "2       11250            7            5          920         2         1   \n",
       "3        9550            7            5          756         1         0   \n",
       "4       14260            8            5         1145         2         1   \n",
       "...       ...          ...          ...          ...       ...       ...   \n",
       "1455     7917            6            5          953         2         1   \n",
       "1456    13175            6            6         1542         2         0   \n",
       "1457     9042            7            9         1152         2         0   \n",
       "1458     9717            5            6         1078         1         0   \n",
       "1459     9937            5            6         1256         1         1   \n",
       "\n",
       "      BedroomAbvGr  TotRmsAbvGrd  Fireplaces  GarageArea  AboveMedianPrice  \n",
       "0                3             8           0         548                 1  \n",
       "1                3             6           1         460                 1  \n",
       "2                3             6           1         608                 1  \n",
       "3                3             7           1         642                 0  \n",
       "4                4             9           1         836                 1  \n",
       "...            ...           ...         ...         ...               ...  \n",
       "1455             3             7           1         460                 1  \n",
       "1456             3             7           2         500                 1  \n",
       "1457             4             9           2         252                 1  \n",
       "1458             2             5           0         240                 0  \n",
       "1459             3             6           0         276                 0  \n",
       "\n",
       "[1460 rows x 11 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Neural\n",
    "import pandas as pd\n",
    "df = pd.read_csv('housepricedata.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9043b6fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8450,     7,     5, ...,     0,   548,     1],\n",
       "       [ 9600,     6,     8, ...,     1,   460,     1],\n",
       "       [11250,     7,     5, ...,     1,   608,     1],\n",
       "       ...,\n",
       "       [ 9042,     7,     9, ...,     2,   252,     1],\n",
       "       [ 9717,     5,     6, ...,     0,   240,     0],\n",
       "       [ 9937,     5,     6, ...,     0,   276,     0]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = df.values\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df8a5903",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:,0:10]\n",
    "Y = dataset[:,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a519acaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0334198 , 0.66666667, 0.5       , ..., 0.5       , 0.        ,\n",
       "        0.3864598 ],\n",
       "       [0.03879502, 0.55555556, 0.875     , ..., 0.33333333, 0.33333333,\n",
       "        0.32440056],\n",
       "       [0.04650728, 0.66666667, 0.5       , ..., 0.33333333, 0.33333333,\n",
       "        0.42877292],\n",
       "       ...,\n",
       "       [0.03618687, 0.66666667, 1.        , ..., 0.58333333, 0.66666667,\n",
       "        0.17771509],\n",
       "       [0.03934189, 0.44444444, 0.625     , ..., 0.25      , 0.        ,\n",
       "        0.16925247],\n",
       "       [0.04037019, 0.44444444, 0.625     , ..., 0.33333333, 0.        ,\n",
       "        0.19464034]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)\n",
    "X_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27e95177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1022, 10) (219, 10) (219, 10) (1022,) (219,) (219,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, Y, test_size=0.3)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5)\n",
    "print(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67b69025",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-15 15:54:08.654358: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-02-15 15:54:08.654380: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-15 15:54:10.477714: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-02-15 15:54:10.477743: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-02-15 15:54:10.477759: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Z238-UL): /proc/driver/nvidia/version does not exist\n",
      "2022-02-15 15:54:10.477933: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 5ms/step - loss: 0.7126 - accuracy: 0.4971 - val_loss: 0.7071 - val_accuracy: 0.5068\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7064 - accuracy: 0.4755 - val_loss: 0.7024 - val_accuracy: 0.4703\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7013 - accuracy: 0.4589 - val_loss: 0.6984 - val_accuracy: 0.4384\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6971 - accuracy: 0.4344 - val_loss: 0.6947 - val_accuracy: 0.4110\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4305 - val_loss: 0.6912 - val_accuracy: 0.4612\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6893 - accuracy: 0.5176 - val_loss: 0.6878 - val_accuracy: 0.5799\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6856 - accuracy: 0.5431 - val_loss: 0.6844 - val_accuracy: 0.5571\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6820 - accuracy: 0.6037 - val_loss: 0.6810 - val_accuracy: 0.5479\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6785 - accuracy: 0.5685 - val_loss: 0.6775 - val_accuracy: 0.5708\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6750 - accuracy: 0.6115 - val_loss: 0.6741 - val_accuracy: 0.5708\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6715 - accuracy: 0.5822 - val_loss: 0.6705 - val_accuracy: 0.6164\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6680 - accuracy: 0.6301 - val_loss: 0.6668 - val_accuracy: 0.6210\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6643 - accuracy: 0.6526 - val_loss: 0.6629 - val_accuracy: 0.6438\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6605 - accuracy: 0.6712 - val_loss: 0.6587 - val_accuracy: 0.6804\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6566 - accuracy: 0.7104 - val_loss: 0.6542 - val_accuracy: 0.7215\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6523 - accuracy: 0.7231 - val_loss: 0.6495 - val_accuracy: 0.7671\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6479 - accuracy: 0.7495 - val_loss: 0.6445 - val_accuracy: 0.8082\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6432 - accuracy: 0.7847 - val_loss: 0.6395 - val_accuracy: 0.8174\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6383 - accuracy: 0.7847 - val_loss: 0.6339 - val_accuracy: 0.8219\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6331 - accuracy: 0.7867 - val_loss: 0.6280 - val_accuracy: 0.8356\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6276 - accuracy: 0.8023 - val_loss: 0.6220 - val_accuracy: 0.8402\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6218 - accuracy: 0.8141 - val_loss: 0.6156 - val_accuracy: 0.8402\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6158 - accuracy: 0.8141 - val_loss: 0.6090 - val_accuracy: 0.8447\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6094 - accuracy: 0.8160 - val_loss: 0.6021 - val_accuracy: 0.8493\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.6027 - accuracy: 0.8209 - val_loss: 0.5949 - val_accuracy: 0.8493\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5957 - accuracy: 0.8219 - val_loss: 0.5877 - val_accuracy: 0.8447\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5884 - accuracy: 0.8229 - val_loss: 0.5797 - val_accuracy: 0.8493\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5807 - accuracy: 0.8229 - val_loss: 0.5715 - val_accuracy: 0.8402\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5728 - accuracy: 0.8268 - val_loss: 0.5628 - val_accuracy: 0.8356\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.8327 - val_loss: 0.5541 - val_accuracy: 0.8402\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5561 - accuracy: 0.8317 - val_loss: 0.5448 - val_accuracy: 0.8402\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.8366 - val_loss: 0.5355 - val_accuracy: 0.8402\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.8356 - val_loss: 0.5258 - val_accuracy: 0.8493\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5288 - accuracy: 0.8425 - val_loss: 0.5160 - val_accuracy: 0.8630\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.8415 - val_loss: 0.5064 - val_accuracy: 0.8539\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.8513 - val_loss: 0.4969 - val_accuracy: 0.8539\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.8434 - val_loss: 0.4866 - val_accuracy: 0.8767\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.8571 - val_loss: 0.4771 - val_accuracy: 0.8767\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.8620 - val_loss: 0.4682 - val_accuracy: 0.8767\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.8611 - val_loss: 0.4586 - val_accuracy: 0.8767\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.8620 - val_loss: 0.4498 - val_accuracy: 0.8767\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.8689 - val_loss: 0.4412 - val_accuracy: 0.8767\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.8708 - val_loss: 0.4331 - val_accuracy: 0.8767\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.8669 - val_loss: 0.4244 - val_accuracy: 0.8721\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.8640 - val_loss: 0.4165 - val_accuracy: 0.8721\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4232 - accuracy: 0.8679 - val_loss: 0.4087 - val_accuracy: 0.8676\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.8669 - val_loss: 0.4015 - val_accuracy: 0.8676\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8718 - val_loss: 0.3948 - val_accuracy: 0.8676\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4024 - accuracy: 0.8689 - val_loss: 0.3885 - val_accuracy: 0.8676\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3960 - accuracy: 0.8728 - val_loss: 0.3830 - val_accuracy: 0.8721\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3902 - accuracy: 0.8689 - val_loss: 0.3759 - val_accuracy: 0.8676\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3844 - accuracy: 0.8748 - val_loss: 0.3702 - val_accuracy: 0.8676\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3797 - accuracy: 0.8718 - val_loss: 0.3651 - val_accuracy: 0.8676\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3740 - accuracy: 0.8757 - val_loss: 0.3611 - val_accuracy: 0.8676\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3695 - accuracy: 0.8748 - val_loss: 0.3563 - val_accuracy: 0.8630\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8728 - val_loss: 0.3511 - val_accuracy: 0.8676\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3610 - accuracy: 0.8757 - val_loss: 0.3467 - val_accuracy: 0.8539\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.8718 - val_loss: 0.3429 - val_accuracy: 0.8584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8777 - val_loss: 0.3392 - val_accuracy: 0.8584\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3498 - accuracy: 0.8728 - val_loss: 0.3359 - val_accuracy: 0.8584\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3462 - accuracy: 0.8748 - val_loss: 0.3322 - val_accuracy: 0.8630\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3434 - accuracy: 0.8767 - val_loss: 0.3290 - val_accuracy: 0.8721\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3414 - accuracy: 0.8748 - val_loss: 0.3262 - val_accuracy: 0.8721\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3376 - accuracy: 0.8816 - val_loss: 0.3235 - val_accuracy: 0.8630\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3351 - accuracy: 0.8748 - val_loss: 0.3208 - val_accuracy: 0.8676\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3328 - accuracy: 0.8787 - val_loss: 0.3184 - val_accuracy: 0.8676\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8738 - val_loss: 0.3159 - val_accuracy: 0.8721\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8757 - val_loss: 0.3137 - val_accuracy: 0.8676\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8757 - val_loss: 0.3116 - val_accuracy: 0.8721\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3245 - accuracy: 0.8787 - val_loss: 0.3097 - val_accuracy: 0.8676\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3221 - accuracy: 0.8787 - val_loss: 0.3093 - val_accuracy: 0.8630\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3208 - accuracy: 0.8787 - val_loss: 0.3061 - val_accuracy: 0.8630\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3186 - accuracy: 0.8777 - val_loss: 0.3054 - val_accuracy: 0.8630\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3173 - accuracy: 0.8767 - val_loss: 0.3026 - val_accuracy: 0.8630\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3162 - accuracy: 0.8826 - val_loss: 0.3015 - val_accuracy: 0.8630\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3139 - accuracy: 0.8787 - val_loss: 0.2994 - val_accuracy: 0.8721\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3133 - accuracy: 0.8816 - val_loss: 0.2980 - val_accuracy: 0.8721\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3119 - accuracy: 0.8796 - val_loss: 0.2965 - val_accuracy: 0.8721\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8787 - val_loss: 0.2951 - val_accuracy: 0.8721\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.8787 - val_loss: 0.2938 - val_accuracy: 0.8721\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.8806 - val_loss: 0.2926 - val_accuracy: 0.8767\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3069 - accuracy: 0.8826 - val_loss: 0.2914 - val_accuracy: 0.8721\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3051 - accuracy: 0.8806 - val_loss: 0.2910 - val_accuracy: 0.8630\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3042 - accuracy: 0.8806 - val_loss: 0.2894 - val_accuracy: 0.8676\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3036 - accuracy: 0.8806 - val_loss: 0.2895 - val_accuracy: 0.8721\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3024 - accuracy: 0.8855 - val_loss: 0.2880 - val_accuracy: 0.8630\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3020 - accuracy: 0.8845 - val_loss: 0.2861 - val_accuracy: 0.8676\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.3003 - accuracy: 0.8836 - val_loss: 0.2848 - val_accuracy: 0.8767\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2998 - accuracy: 0.8875 - val_loss: 0.2842 - val_accuracy: 0.8676\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2989 - accuracy: 0.8875 - val_loss: 0.2835 - val_accuracy: 0.8676\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2981 - accuracy: 0.8875 - val_loss: 0.2822 - val_accuracy: 0.8721\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2969 - accuracy: 0.8845 - val_loss: 0.2811 - val_accuracy: 0.8721\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2960 - accuracy: 0.8845 - val_loss: 0.2802 - val_accuracy: 0.8676\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2956 - accuracy: 0.8904 - val_loss: 0.2795 - val_accuracy: 0.8721\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2945 - accuracy: 0.8806 - val_loss: 0.2790 - val_accuracy: 0.8676\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2937 - accuracy: 0.8865 - val_loss: 0.2776 - val_accuracy: 0.8721\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2936 - accuracy: 0.8806 - val_loss: 0.2769 - val_accuracy: 0.8721\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2923 - accuracy: 0.8904 - val_loss: 0.2760 - val_accuracy: 0.8721\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2913 - accuracy: 0.8865 - val_loss: 0.2769 - val_accuracy: 0.8767\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2903 - accuracy: 0.8845 - val_loss: 0.2745 - val_accuracy: 0.8721\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(10,)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid'),\n",
    "])\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "hist = model.fit(X_train, Y_train,\n",
    "          batch_size=32, epochs=100,\n",
    "          validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6ea4c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2743 - accuracy: 0.8858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8858447670936584"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43deeeaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "492537b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4022/2618872337.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "plt.plot(hist.history['acc'])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39633ee4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
